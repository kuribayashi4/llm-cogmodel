{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "\n",
    "def create_prompt(df, data, word_field=\"word\"):\n",
    "    random.seed(42)\n",
    "    sents = []\n",
    "    for sent_id, sent in groupby(df[[word_field, \"time\", \"sent_id\", \"article\"]].iterrows(), key=lambda x: x[1][2]):\n",
    "        sent = list(sent)\n",
    "        sents.append([(\"\".join(tok[1][0].split()).replace(\"▁\", \" \").strip(), tok[1][1]) for tok in sent])\n",
    "\n",
    "    for i in range(3):\n",
    "        print(i)\n",
    "        j = 0\n",
    "        with open(f\"../data/{data}/prompts/prompt_{i}.txt\", \"w\") as f:\n",
    "            while j < 3:\n",
    "                selected_sent = random.choice(sents)\n",
    "                sent = \" \".join([tok[0] for tok in selected_sent])\n",
    "                tok_time_id = [(tok[0], tok[1], i) for i, tok in enumerate(selected_sent)]\n",
    "                if min([time for tok, time, id in tok_time_id]) == 0:\n",
    "                    continue\n",
    "                f.write(f'Suppose humans read the following sentence: \"{sent}\" \\nList the tokens and their IDs in order of their reading cost (high to low) during sentence processing.\\n')\n",
    "                f.write(\"Token ID:\\n\")\n",
    "                for tok, time, id in tok_time_id:\n",
    "                    f.write(f\"{id}: {tok}, \")\n",
    "                f.write(\"\\n\")\n",
    "                sorted_sent = sorted(tok_time_id, key=lambda x: x[1], reverse=True)\n",
    "                f.write(\"Answer:\\n\" + \" \".join(f\"{id}: {tok},\" for tok, time, id in sorted_sent) + \"\\n\\n\")\n",
    "                j += 1\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_surprisal_prompt(df, data, model, word_field=\"word\"):\n",
    "    random.seed(42)\n",
    "    target_file = f\"../results/{data}/{model}/surprisal.json\"\n",
    "    article2surprisals = json.load(open(target_file))\n",
    "    all_sups = [sup for _, sents_sups in sorted(article2surprisals.items(), key=lambda x: int(x[0])) for sent_sups in sents_sups for sup in sent_sups]\n",
    "    assert len(df) == len(all_sups)\n",
    "    df[\"surprisal\"] = all_sups\n",
    "\n",
    "    sents = []\n",
    "    for sent_id, sent in groupby(df[[word_field, \"surprisal\", \"sent_id\", \"article\"]].iterrows(), key=lambda x: x[1][2]):\n",
    "        sent = list(sent)\n",
    "        sents.append([(\"\".join(tok[1][0].split()).replace(\"▁\", \" \").strip(), tok[1][1]) for tok in sent])\n",
    "\n",
    "    for i in range(3):\n",
    "        print(i)\n",
    "        j = 0\n",
    "        with open(f\"../data/{data}/prompts/prompt_surprisal_{model}_{i}.txt\", \"w\") as f:\n",
    "            while j < 3:\n",
    "                selected_sent = random.choice(sents)\n",
    "                sent = \" \".join([tok[0] for tok in selected_sent])\n",
    "                tok_time_id = [(tok[0], tok[1], i) for i, tok in enumerate(selected_sent)]\n",
    "                if min([time for tok, time, id in tok_time_id]) == 0:\n",
    "                    continue\n",
    "                f.write(f'Suppose you read the following sentence: \"{sent}\" \\nList the tokens and their IDs in order of their probability in context (low to high).\\n')\n",
    "                f.write(\"Token ID:\\n\")\n",
    "                for tok, time, id in tok_time_id:\n",
    "                    f.write(f\"{id}: {tok}, \")\n",
    "                f.write(\"\\n\")\n",
    "                sorted_sent = sorted(tok_time_id, key=lambda x: x[1], reverse=True)\n",
    "                f.write(\"Answer:\\n\" + \" \".join(f\"{id}: {tok},\" for tok, time, id in sorted_sent) + \"\\n\\n\")\n",
    "                j += 1\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/DC/all.txt.annotation.filtered.averaged_rt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sents = create_prompt(df, \"DC\", word_field=\"surface\")\n",
    "models = [\"Llama-2-7b-chat-hf\", \"Llama-2-13b-chat-hf\", \"Llama-2-70b-chat-hf\", \"gpt-3.5-turbo-instruct\", \"falcon-7b-instruct\", \"falcon-40b-instruct\", \"text-davinci-002\", \"text-davinci-003\"]\n",
    "for model in models:\n",
    "    sents = create_surprisal_prompt(df, \"DC\", model, word_field=\"surface\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/NS/all.txt.annotation.filtered.averaged_rt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sents = create_prompt(df, \"NS\", word_field=\"word\")\n",
    "models = [\"Llama-2-7b-chat-hf\", \"Llama-2-13b-chat-hf\", \"Llama-2-70b-chat-hf\", \"gpt-3.5-turbo-instruct\", \"falcon-7b-instruct\", \"falcon-40b-instruct\", \"text-davinci-002\", \"text-davinci-003\"]\n",
    "models = [\"Mistral-7B-Instruct-v0.1\"]\n",
    "for model in models:\n",
    "    sents = create_surprisal_prompt(df, \"NS\", model, word_field=\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppose humans read the following sentence: \"The 'tulip breaking' virus, which many botanists have studied, spreads only through buds, not seeds, and so cultivating the most appealing varieties takes years.\" \n",
      "List the tokens and their IDs in order of their reading cost (high to low) during sentence processing.\n",
      "Token ID:\n",
      "0:The, 1:'tulip, 2:breaking', 3:virus,, 4:which, 5:many, 6:botanists, 7:have, 8:studied,, 9:spreads, 10:only, 11:through, 12:buds,, 13:not, 14:seeds,, 15:and, 16:so, 17:cultivating, 18:the, 19:most, 20:appealing, 21:varieties, 22:takes, 23:years., \n",
      "Answer:\n",
      "Answer:\n",
      "13: not, 8: studied,, 12: buds,, 2: breaking', 22: takes, 17: cultivating, 3: virus,, 20: appealing, 21: varieties, 0: The, 14: seeds,, 15: and, 16: so, 1: 'tulip, 4: which, 11: through, 6: botanists, 5: many, 19: most, 10: only, 9: spreads, 7: have, 18: the, 23: years.,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_sent = random.choice(sents)\n",
    "sent = \" \".join([tok[0] for tok in target_sent])\n",
    "print(f'Suppose humans read the following sentence: \"{sent}\" \\nList the tokens and their IDs in order of their reading cost (high to low) during sentence processing.')\n",
    "tok_time_id = [(tok[0], tok[1], i) for i, tok in enumerate(target_sent)]\n",
    "print(\"Token ID:\")\n",
    "for tok, time, id in tok_time_id:\n",
    "    print(f\"{id}:{tok},\", end = \" \")\n",
    "print()\n",
    "print(\"Answer:\")\n",
    "sorted_sent = sorted(tok_time_id, key=lambda x: x[1], reverse=True)\n",
    "print(\"Answer:\\n\" + \" \".join(f\"{id}: {tok},\" for tok, time, id in sorted_sent) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
